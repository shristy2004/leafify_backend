# -*- coding: utf-8 -*-
"""Untitled8.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1lkAKlq6pyRN74WV04EhCW4NbuuRt8Z9C
"""

from google.colab import drive
drive.mount('/content/drive')

import kagglehub
path = kagglehub.dataset_download("vipoooool/new-plant-diseases-dataset")
path = "/kaggle/input/new-plant-diseases-dataset/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)"
train = "/kaggle/input/new-plant-diseases-dataset/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/train"
valid = "/kaggle/input/new-plant-diseases-dataset/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/valid"
test  = "/kaggle/input/new-plant-diseases-dataset/test"

import warnings
warnings.filterwarnings('ignore')

import os
import json
import pickle

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

from PIL import Image

import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader

import torchvision
from torchvision import transforms
from torchvision.datasets import ImageFolder

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder

from tqdm import tqdm
!pip install colorama
import colorama
from colorama import Fore, Style
!pip install torchinfo

import matplotlib.pyplot as plt
import random
import os
from PIL import Image
import numpy as np
import kagglehub
Diseases_classes = os.listdir(train)
def display_disease_samples(data_dir, plants=None, num_cols=5):
    disease_folders = sorted([f for f in os.listdir(data_dir) if os.path.isdir(os.path.join(data_dir, f))])

    if plants is not None:
        disease_folders = [f for f in disease_folders if any(p in f for p in plants)]

    num_diseases = len(disease_folders)
    num_rows = (num_diseases + num_cols - 1) // num_cols
    fig, axes = plt.subplots(num_rows, num_cols, figsize=(20, 4 * num_rows))
    axes = axes.flatten() if num_rows > 1 else axes

    for i, disease_folder in enumerate(disease_folders):
        folder_path = os.path.join(data_dir, disease_folder)

        img_files = [f for f in os.listdir(folder_path) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]
        if img_files:
            img_path = os.path.join(folder_path, random.choice(img_files))
            img = Image.open(img_path).convert('RGB')

            disease_name = disease_folder.replace('_', ' ')

            axes[i].imshow(img)
            axes[i].set_title(disease_name, fontsize=12)
            axes[i].axis('off')

    for j in range(i + 1, len(axes)):
        fig.delaxes(axes[j])

    plt.tight_layout()
    plt.show()

print("üåø Sample images from different plant disease categories:")
display_disease_samples(test)

Root_dir = path
train_dir = Root_dir + "/train"
valid_dir = Root_dir + "/valid"
test_dir = test
Diseases_classes = os.listdir(train_dir)
print(Fore.GREEN +str(Diseases_classes))
print("\nTotal number of classes are: ", len(Diseases_classes))
plt.figure(figsize=(60,60), dpi=200)
cnt = 0
plant_names = []
tot_images = 0

for i in Diseases_classes:
    cnt += 1
    plant_names.append(i)
    plt.subplot(7,7,cnt)

    image_path = os.listdir(train_dir + "/" + i)
    print(Fore.GREEN)
    print("The Number of Images in " +i+ ":", len(image_path), end= " ")
    tot_images += len(image_path)

    img_show = plt.imread(train_dir + "/" + i + "/" + image_path[0])

    plt.imshow(img_show)
    plt.xlabel(i,fontsize=30)
    plt.xticks([])
    plt.yticks([])


print("\nTotal Number of Images in Directory: ", tot_images)

# Dataset Class
class PlantDiseaseDataset(Dataset):
    """Custom Dataset for loading plant disease images"""
    def __init__(self, image_paths, labels, transform=None):
        self.image_paths = image_paths
        self.labels = labels
        self.transform = transform

    def __len__(self):
        return len(self.labels)

    def __getitem__(self, idx):
        img_path = self.image_paths[idx]
        label = self.labels[idx]

        # Load the image and apply transformations
        img = Image.open(img_path).convert("RGB")
        if self.transform:
            img = self.transform(img)

        return img, torch.tensor(label, dtype=torch.long)

from torchinfo import summary

class PlantDiseaseModel(nn.Module):
    """Convolutional Neural Network for plant disease classification"""
    def __init__(self, num_classes, dropout_rate=0.5):
        super(PlantDiseaseModel, self).__init__()
        # Convolutional Block 1
        self.conv_block1 = nn.Sequential(
            nn.Conv2d(3, 64, kernel_size=3, padding="same"),
            nn.BatchNorm2d(64),
            nn.ReLU(),
            nn.MaxPool2d(kernel_size=2)
        )
        # Convolutional Block 2
        self.conv_block2 = nn.Sequential(
            nn.Conv2d(64, 128, kernel_size=3, padding="same"),
            nn.BatchNorm2d(128),
            nn.ReLU(),
            nn.MaxPool2d(kernel_size=2)
        )
        # Convolutional Block 3
        self.conv_block3 = nn.Sequential(
            nn.Conv2d(128, 256, kernel_size=3, padding="same"),
            nn.BatchNorm2d(256),
            nn.ReLU(),
            nn.MaxPool2d(kernel_size=2)
        )
        # Convolutional Block 4
        self.conv_block4 = nn.Sequential(
            nn.Conv2d(256, 512, kernel_size=3, padding="same"),
            nn.BatchNorm2d(512),
            nn.ReLU(),
            nn.MaxPool2d(kernel_size=2)
        )
        # Convolutional Block 5
        self.conv_block5 = nn.Sequential(
            nn.Conv2d(512, 512, kernel_size=3, padding="same"),
            nn.BatchNorm2d(512),
            nn.ReLU(),
            nn.MaxPool2d(kernel_size=2)
        )
        # Global Average Pooling
        self.global_avg_pool = nn.AdaptiveAvgPool2d((1, 1))
        # Fully Connected Layers
        self.fc_block = nn.Sequential(
            nn.Flatten(),
            nn.Linear(512, 256),
            nn.ReLU(),
            nn.Dropout(dropout_rate),
            nn.Linear(256, num_classes)
        )

    def forward(self, x):
        x = self.conv_block1(x)
        x = self.conv_block2(x)
        x = self.conv_block3(x)
        x = self.conv_block4(x)
        x = self.conv_block5(x)
        x = self.global_avg_pool(x)
        x = self.fc_block(x)
        return x

print(summary(PlantDiseaseModel(15), input_size=(1, 3, 224, 224)))

# Early Stopping Utility
class EarlyStopping:
    """Early stopping handler to prevent overfitting"""
    def __init__(self, patience=5, min_delta=0.001, save_path="best_model.pth"):
        self.patience = patience
        self.min_delta = min_delta
        self.save_path = save_path
        self.best_loss = float('inf')
        self.counter = 0

    def __call__(self, val_loss, model):
        if val_loss < self.best_loss - self.min_delta:
            self.best_loss = val_loss
            self.counter = 0
            # Save the best model
            torch.save(model.state_dict(), self.save_path)
            print(f"[INFO] Model checkpoint saved to {self.save_path}")
            return False
        else:
            self.counter += 1
            if self.counter >= self.patience:
                print("[INFO] Early stopping triggered.")
                return True
        return False

from torchvision.datasets import ImageFolder
from torchvision import transforms

train = train
valid = valid

train = ImageFolder(train, transform=transforms.ToTensor())
valid = ImageFolder(valid, transform=transforms.ToTensor())

train

train[0]

train[7000]

train[70000]

img, label = train[0]
print(img.shape, label)

def show_augmentations(data_dir, num_plants=3):
    disease_folders = [f for f in os.listdir(data_dir) if os.path.isdir(os.path.join(data_dir, f))]
    selected_folders = random.sample(disease_folders, min(num_plants, len(disease_folders)))

    # Define augmentations to display like the training used one.
    augmentations = [
        ("Original", transforms.Compose([
            transforms.Resize((256, 256)),
            transforms.ToTensor()
        ])),
        ("Horizontal Flip", transforms.Compose([
            transforms.Resize((256, 256)),
            transforms.RandomHorizontalFlip(p=1.0),
            transforms.ToTensor()
        ])),
        ("Rotation (30¬∞)", transforms.Compose([
            transforms.Resize((256, 256)),
            transforms.RandomRotation(30),
            transforms.ToTensor()
        ])),
        ("Color Jitter", transforms.Compose([
            transforms.Resize((256, 256)),
            transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),
            transforms.ToTensor()
        ])),
        ("Combined", transforms.Compose([
            transforms.Resize((256, 256)),
            transforms.RandomHorizontalFlip(),
            transforms.RandomRotation(20),
            transforms.ColorJitter(brightness=0.1, contrast=0.1),
            transforms.ToTensor()
        ]))
    ]

    fig, axes = plt.subplots(len(selected_folders), len(augmentations), figsize=(18, 4 * len(selected_folders)))

    for i, folder in enumerate(selected_folders):
        folder_path = os.path.join(data_dir, folder)

        img_files = [f for f in os.listdir(folder_path) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]
        if not img_files:
            continue

        img_path = os.path.join(folder_path, random.choice(img_files))
        original_img = Image.open(img_path).convert('RGB')

        for j, (aug_name, transform) in enumerate(augmentations):
            img_tensor = transform(original_img)

            img_np = img_tensor.permute(1, 2, 0).numpy()

            ax = axes[i, j] if len(selected_folders) > 1 else axes[j]
            ax.imshow(img_np)

            if i == 0:
                ax.set_title(aug_name, fontsize=12)

            if j == 0:
                disease_name = folder.replace('_', ' ')
                ax.set_ylabel(disease_name, fontsize=10)

            ax.axis('off')

    plt.tight_layout()
    plt.suptitle("Data Augmentation Techniques for Plant Disease Images", fontsize=20, y=1.0)
    plt.show()

show_augmentations(test)

def show_image(image, label):
    print("Label :" + train.classes[label] + "(" + str(label) + ")")
    plt.imshow(image.permute(1, 2, 0))


image_list = [0, 3000, 5000, 8000, 12000, 15000, 60000, 70000]

chs = 0
for img in image_list:
    chs += 1
    plt.subplot(2,4,chs)
    print(Fore.GREEN)
    plt.tight_layout()
    plt.xlabel(img,fontsize=10)
    plt.title(train[img][1])
    show_image(*train[img])

batch_size = 32

# DataLoaders for training and validation
train_dataloader = DataLoader(train, batch_size, shuffle=True, num_workers=2, pin_memory=True)
valid_dataloader = DataLoader(valid, batch_size, num_workers=2, pin_memory=True)

# for moving data into GPU (if available)
def get_default_device():
    """Pick GPU if available, else CPU"""
    if torch.cuda.is_available:
        return torch.device("cuda")
    else:
        return torch.device("cpu")

# for moving data to device (CPU or GPU)
def to_device(data, device):
    """Move tensor(s) to chosen device"""
    if isinstance(data, (list,tuple)):
        return [to_device(x, device) for x in data]
    return data.to(device, non_blocking=True)

# for loading in the device (GPU if available else CPU)
class DeviceDataLoader():
    """Wrap a dataloader to move data to a device"""
    def __init__(self, dataloader, device):
        self.dataloader = dataloader
        self.device = device

    def __iter__(self):
        """Yield a batch of data after moving it to device"""
        for b in self.dataloader:
            yield to_device(b, self.device)

    def __len__(self):
        """Number of batches"""
        return len(self.dataloader)

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
device

# Moving data into GPU, WrappedDataLoader
train_dataloader = DeviceDataLoader(train_dataloader, device)
valid_dataloader = DeviceDataLoader(valid_dataloader, device)

# for calculating the accuracy
def accuracy(outputs, labels):
    _, preds = torch.max(outputs, dim=1)
    return torch.tensor(torch.sum(preds == labels).item() / len(preds))

class ImageClassificationBase(nn.Module):

    def training_step(self, batch):
        images, labels = batch
        out = self(images)                  # Generate predictions
        loss = F.cross_entropy(out, labels) # Calculate loss
        return loss

    def validation_step(self, batch):
        images, labels = batch
        out = self(images)                    # Generate predictions
        loss = F.cross_entropy(out, labels)   # Calculate loss
        acc = accuracy(out, labels)           # Calculate accuracy
        return {'val_loss': loss.detach(), 'val_acc': acc}

    def validation_epoch_end(self, outputs):
        batch_losses = [x['val_loss'] for x in outputs]
        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses
        batch_accs = [x['val_acc'] for x in outputs]
        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies
        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}

    def epoch_end(self, epoch, result):
        print("Epoch [{}], train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}".format(
            epoch, result['train_loss'], result['val_loss'], result['val_acc']))

# convolution block with BatchNormalization
def ConvBlock(in_channels, out_channels, pool=False):
    layers = [nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),
             nn.BatchNorm2d(out_channels),
             nn.ReLU(inplace=True)]
    if pool:
        layers.append(nn.MaxPool2d(4))
    return nn.Sequential(*layers)

# resnet architecture
class CNN_NeuralNet(ImageClassificationBase):
    def __init__(self, in_channels, num_diseases):
        super().__init__()

        self.conv1 = ConvBlock(in_channels, 64)
        self.conv2 = ConvBlock(64, 128, pool=True)
        self.res1 = nn.Sequential(ConvBlock(128, 128), ConvBlock(128, 128))

        self.conv3 = ConvBlock(128, 256, pool=True)
        self.conv4 = ConvBlock(256, 512, pool=True)
        #self.conv5 = ConvBlock(256, 256, pool=True)
        #self.conv6 = ConvBlock(256, 512, pool=True)
        #self.conv7 = ConvBlock(512, 512, pool=True)

        self.res2 = nn.Sequential(ConvBlock(512, 512), ConvBlock(512, 512))
        self.classifier = nn.Sequential(nn.MaxPool2d(4),
                                       nn.Flatten(),
                                       nn.Linear(512, num_diseases))

    def forward(self, x): # x is the loaded batch
        out = self.conv1(x)
        out = self.conv2(out)
        out = self.res1(out) + out
        out = self.conv3(out)
        out = self.conv4(out)
        #out = self.conv5(out)
        #out = self.conv6(out)
        #out = self.conv7(out)
        out = self.res2(out) + out
        out = self.classifier(out)
        return out

# defining the model and moving it to the GPU
# 3 is number of channels RGB, len(train.classes()) is number of diseases.
model = to_device(CNN_NeuralNet(3, len(train.classes)), device)
model

# for training
@torch.no_grad()
def evaluate(model, val_loader):
    model.eval()
    outputs = [model.validation_step(batch) for batch in val_loader]
    return model.validation_epoch_end(outputs)
def get_lr(optimizer):
    for param_group in optimizer.param_groups:
        return param_group['lr']

def fit_OneCycle(epochs, max_lr, model, train_loader, val_loader, weight_decay=0,
                grad_clip=None, opt_func=torch.optim.SGD):
    torch.cuda.empty_cache()
    history = []  #For collecting the results

    optimizer = opt_func(model.parameters(), max_lr, weight_decay=weight_decay)
    # scheduler for one cycle learniing rate
    #Sets the learning rate of each parameter group according to the 1cycle learning rate policy.
    #The 1cycle policy anneals the learning rate from an initial learning rate to some
    #maximum learning rate and then from that maximum learning rate to some minimum learning rate
    #much lower than the initial learning rate.
    sched = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr,
                                                epochs=epochs, steps_per_epoch=len(train_loader))


    for epoch in range(epochs):
        # Training
        model.train()
        train_losses = []
        lrs = []
        for batch in train_loader:
            loss = model.training_step(batch)
            train_losses.append(loss)
            loss.backward()

            # gradient clipping
            #Clip the gradients of an iterable of parameters at specified value.
            #All from pytorch documantation.
            if grad_clip:
                nn.utils.clip_grad_value_(model.parameters(), grad_clip)

            optimizer.step()
            optimizer.zero_grad()

            # recording and updating learning rates
            lrs.append(get_lr(optimizer))
            sched.step()
             # validation

        result = evaluate(model, val_loader)
        result['train_loss'] = torch.stack(train_losses).mean().item()
        result['lrs'] = lrs
        model.epoch_end(epoch, result)
        history.append(result)

    return history

def evaluate_by_plant_type(model, test_loader, label_encoder, device):
    """Evaluate model performance separately for each plant type with enhanced visualization"""
    model.eval()

    # Prepare containers for per-class metrics
    class_correct = {}
    class_total = {}

    # Get all predictions
    all_preds = []
    all_labels = []
    with torch.no_grad():
        for inputs, labels in test_loader:
            inputs, labels = inputs.to(device), labels.to(device)
            outputs = model(inputs)
            _, preds = torch.max(outputs, 1)

            # Store predictions and true labels
            all_preds.extend(preds.cpu().numpy())
            all_labels.extend(labels.cpu().numpy())

            # Update per-class counts
            for i, label in enumerate(labels):
                label_idx = label.item()
                label_name = label_encoder.inverse_transform([label_idx])[0]

                if label_name not in class_correct:
                    class_correct[label_name] = 0
                    class_total[label_name] = 0

                class_total[label_name] += 1
                if preds[i] == label:
                    class_correct[label_name] += 1

    # Extract plant types from class names
    plants = {}
    for class_name in class_correct.keys():
        if "__" in class_name:
            plant = class_name.split("__")[0].replace("_", " ")
        else:
            plant = class_name.split("_")[0]

        if plant not in plants:
            plants[plant] = {"correct": 0, "total": 0}

        plants[plant]["correct"] += class_correct[class_name]
        plants[plant]["total"] += class_total[class_name]

    # Compute accuracy per plant type
    plant_accuracy = {p: (stats["correct"] / stats["total"]) * 100
                     for p, stats in plants.items()}

    # Sort plants by accuracy for better visual comparison
    sorted_plants = dict(sorted(plant_accuracy.items(), key=lambda x: x[1], reverse=True))

    # Enhanced Visualization
    plt.style.use('ggplot')
    fig = plt.figure(figsize=(16, 10))
    ax = fig.add_subplot(111)

    # Improved color configuration
    colors = plt.cm.RdYlGn(np.linspace(0.2, 0.8, len(sorted_plants)))

    # Calculate average accuracy
    avg_accuracy = np.mean(list(plant_accuracy.values()))

    # Create bars with enhanced styling
    plants_list = list(sorted_plants.keys())
    accuracies = list(sorted_plants.values())
    totals = [plants[p]["total"] for p in plants_list]

    # Create gradient background
    ax.set_facecolor('#f8f9fa')
    fig.patch.set_facecolor('#ffffff')

    # Create enhanced bars
    bars = ax.bar(plants_list, accuracies, color=colors, edgecolor='#505050',
                 linewidth=1, alpha=0.85, width=0.7)

    # Add drop shadow effect to bars
    for bar in bars:
        x, y = bar.get_xy()
        w, h = bar.get_width(), bar.get_height()
        shadow = plt.Rectangle((x+0.03, y-0.03), w, h, color='#00000022', zorder=0)
        ax.add_patch(shadow)

    # Add annotations with improved styling
    for bar, acc, total in zip(bars, accuracies, totals):
        height = bar.get_height()
        # Add accuracy labels
        ax.text(bar.get_x() + bar.get_width()/2., height + 1,
               f'{acc:.1f}%',
               ha='center', va='bottom',
               fontsize=11, fontweight='bold',
               bbox=dict(boxstyle="round,pad=0.3", fc='white', ec="grey", alpha=0.8))

        # Add sample size labels
        ax.text(bar.get_x() + bar.get_width()/2., height/2,
               f'n={total}',
               ha='center', va='center',
               fontsize=10, color='#303030',
               fontweight='bold', rotation=0)

    # Add reference lines and styling
    ax.axhline(avg_accuracy, color='#e74c3c', linestyle='-', linewidth=2.5, alpha=0.7)
    ax.axhline(avg_accuracy, color='#c0392b', linestyle='-', linewidth=1, alpha=1)

    # Add average line label with enhanced styling
    ax.text(len(plants_list)-0.5, avg_accuracy + 3,
           f' Average: {avg_accuracy:.1f}%',
           color='#c0392b', fontsize=13, ha='right', va='bottom',
           fontweight='bold',
           bbox=dict(boxstyle="round,pad=0.3", fc='white', ec="#c0392b", alpha=0.8))

    # Configure axes and labels with enhanced styling
    ax.set_title(f'Model Accuracy by Plant Type\n{model.__class__.__name__} Performance Analysis',
                fontsize=18, pad=20, fontweight='bold', color='#2c3e50')

    ax.set_xlabel('Plant Type', fontsize=14, labelpad=15, fontweight='bold', color='#2c3e50')
    ax.set_ylabel('Accuracy (%)', fontsize=14, labelpad=15, fontweight='bold', color='#2c3e50')

    # Add a subtle box around the plot
    for spine in ax.spines.values():
        spine.set_visible(True)
        spine.set_color('#cccccc')
        spine.set_linewidth(1)

    # Enhanced tick parameters
    ax.tick_params(axis='x', rotation=45, labelsize=12, pad=5, colors='#2c3e50')
    ax.tick_params(axis='y', labelsize=12, pad=5, colors='#2c3e50')
    ax.set_ylim(0, max(accuracies) * 1.15)

    # Add customized grid
    ax.yaxis.grid(True, linestyle='--', alpha=0.4, color='#95a5a6')
    ax.set_axisbelow(True)

    # Add a subtle top performance indicator
    top_performer = plants_list[0]
    top_accuracy = accuracies[0]
    ax.text(0, max(accuracies) * 1.1,
           f"Top Performer: {top_performer} ({top_accuracy:.1f}%)",
           fontsize=12, ha='left', color='#27ae60',
           bbox=dict(boxstyle="round,pad=0.3", fc='#f8f9fa', ec="#2ecc71", alpha=0.8))

    # Add watermark or model info
    fig.text(0.95, 0.02, f"{model.__class__.__name__}",
             fontsize=10, color='gray', ha='right', va='bottom', alpha=0.7)

    plt.tight_layout()
    plt.show()

    return plant_accuracy

# Training and Evaluation Functions
def evaluate_model(model, data_loader, criterion, device):
    """Evaluate model on validation or test set"""
    model.eval()
    val_loss = 0.0
    correct, total = 0, 0
    all_preds = []
    all_labels = []

    with torch.no_grad():
        progress_bar = tqdm(enumerate(data_loader), desc="Evaluating", total=len(data_loader))
        for batch_idx, (inputs, labels) in progress_bar:
            inputs, labels = inputs.to(device), labels.to(device)
            # Forward pass
            outputs = model(inputs)
            loss = criterion(outputs, labels)

            val_loss += loss.item()
            _, predicted = torch.max(outputs, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()

            all_preds.extend(predicted.cpu().numpy())
            all_labels.extend(labels.cpu().numpy())

            progress_bar.set_postfix({"Val Loss": loss.item(), "Accuracy": correct / total * 100})

    val_loss /= len(data_loader)
    accuracy = correct / total * 100
    return val_loss, accuracy, np.array(all_preds), np.array(all_labels)

def train_model(model, train_loader, valid_loader, criterion, optimizer, scheduler=None,
                epochs=10, early_stopping=None, device="cpu"):
    """Train the model with optional early stopping and learning rate scheduler"""
    model.to(device)
    train_losses, valid_losses, valid_accuracies = [], [], []

    for epoch in range(epochs):
        model.train()
        running_loss = 0.0
        progress_bar = tqdm(enumerate(train_loader), desc=f"Epoch {epoch+1}/{epochs}",
                           total=len(train_loader))

        for batch_idx, (inputs, labels) in progress_bar:
            inputs, labels = inputs.to(device), labels.to(device)

            # Forward pass
            outputs = model(inputs)
            loss = criterion(outputs, labels)

            # Backward pass
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()

            running_loss += loss.item()
            progress_bar.set_postfix({"Train Loss": loss.item()})

        # Record training loss
        train_loss = running_loss / len(train_loader)
        train_losses.append(train_loss)

        # Validation step
        val_loss, val_accuracy, _, _ = evaluate_model(model, valid_loader, criterion, device)
        valid_losses.append(val_loss)
        valid_accuracies.append(val_accuracy)

        # Print epoch summary
        print(f"Epoch {epoch+1}: Train Loss = {train_loss:.4f}, Val Loss = {val_loss:.4f}, "
              f"Val Accuracy = {val_accuracy:.2f}%")

        # Learning rate scheduler step
        if scheduler:
            scheduler.step(val_loss)

        # Early stopping
        if early_stopping and early_stopping(val_loss, model):
            print("[INFO] Early stopping triggered.")
            break

    # Save the learning curves
    save_learning_curves(train_losses, valid_losses, valid_accuracies)

    return train_losses, valid_losses, valid_accuracies

def save_learning_curves(train_losses, valid_losses, valid_accuracies):
    """Save learning curves as a plot"""
    plt.figure(figsize=(12, 5))

    # Plot training and validation loss
    plt.subplot(1, 2, 1)
    plt.plot(train_losses, label='Training Loss')
    plt.plot(valid_losses, label='Validation Loss')
    plt.xlabel('Epochs')
    plt.ylabel('Loss')
    plt.legend()
    plt.title('Training and Validation Loss')

    # Plot validation accuracy
    plt.subplot(1, 2, 2)
    plt.plot(valid_accuracies, label='Validation Accuracy')
    plt.xlabel('Epochs')
    plt.ylabel('Accuracy (%)')
    plt.legend()
    plt.title('Validation Accuracy')

    plt.tight_layout()
    plt.savefig('learning_curves.png')
    plt.close()

# Prediction function for inference
def predict_image(model, image_path, transform, device, label_encoder=None):
    """Make prediction on a single image"""
    model.eval()

    # Open and transform the image
    image = Image.open(image_path).convert("RGB")
    image_tensor = transform(image).unsqueeze(0).to(device)

    # Make prediction
    with torch.no_grad():
        outputs = model(image_tensor)
        _, predicted = torch.max(outputs, 1)
        probabilities = torch.nn.functional.softmax(outputs, dim=1)

    predicted_idx = predicted.item()
    confidence = probabilities[0][predicted_idx].item() * 100

    if label_encoder:
        predicted_class = label_encoder.inverse_transform([predicted_idx])[0]
        return predicted_class, confidence, probabilities[0].cpu().numpy()
    else:
        return predicted_idx, confidence, probabilities[0].cpu().numpy()

# Main function to train the model
def train(data_dir, model_save_path="best_model.pth", batch_size=32,
          epochs=30, learning_rate=0.001, image_size=(256, 256)):
    """Main function to train and save the model and necessary files for deployment"""
    # Prepare data
    train_loader, valid_loader, test_loader, num_classes = prepare_data(
        data_dir, image_size=image_size, batch_size=batch_size
    )

    # Setup device
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"Using device: {device}")

    # Initialize model, loss function, optimizer and scheduler
    model = PlantDiseaseModel(num_classes=num_classes, dropout_rate=0.5)
    model.to(device)
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=learning_rate)
    scheduler = optim.lr_scheduler.ReduceLROnPlateau(
        optimizer, mode='min', factor=0.1, patience=3, verbose=True
    )
    early_stopping = EarlyStopping(patience=7, min_delta=0.001, save_path=model_save_path)

    # Print model summary
    print(f"Model created with {num_classes} output classes")

    # Train the model
    train_model(
        model=model,
        train_loader=train_loader,
        valid_loader=valid_loader,
        criterion=criterion,
        optimizer=optimizer,
        scheduler=scheduler,
        epochs=epochs,
        early_stopping=early_stopping,
        device=device
    )

    # Load the best model
    model.load_state_dict(torch.load(model_save_path))

    # Evaluate on test set
    print("\n[INFO] Evaluating the model on the test set...")
    test_loss, test_accuracy, predictions, true_labels = evaluate_model(
        model, test_loader, criterion, device
    )
    print(f"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.2f}%")

    # Save model architecture for inference
    dummy_input = torch.randn(1, 3, *image_size).to(device)
    torch.onnx.export(model, dummy_input, "plant_disease_model.onnx")

    # Save model config
    model_config = {
        "image_size": image_size,
        "num_classes": num_classes,
        "model_path": model_save_path,
        "label_encoder_path": "label_encoder.pkl",
        "transform_path": "inference_transform.pkl",
        "class_names_path": "class_names.json"
    }

    with open("model_config.json", "w") as f:
        json.dump(model_config, f)

    print("[INFO] Training completed and all necessary files saved for deployment.")
    return model, model_config

import kagglehub
path = kagglehub.dataset_download("vipoooool/new-plant-diseases-dataset")

# Correct dataset paths
train_dir = "/kaggle/input/new-plant-diseases-dataset/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/train"
valid_dir = "/kaggle/input/new-plant-diseases-dataset/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/valid"
test_dir  = "/kaggle/input/new-plant-diseases-dataset/test"

# -------------------------------------------------
# FAST EfficientNet Training Script
# -------------------------------------------------

import torch
from torch import nn, optim
from torch.utils.data import DataLoader
from torchvision import datasets, transforms, models
import time

# -------------------------------
# 1. Device
# -------------------------------
device = "cuda" if torch.cuda.is_available() else "cpu"
print("Using device:", device)

# -------------------------------
# 2. Fast Augmentations + Resize
# -------------------------------
train_tf = transforms.Compose([
    transforms.Resize((128, 128)),
    transforms.RandomHorizontalFlip(),
    transforms.RandomRotation(10),
    transforms.ToTensor()
])

valid_tf = transforms.Compose([
    transforms.Resize((128, 128)),
    transforms.ToTensor()
])

# -------------------------------
# 3. Load Datasets From YOUR PATH
# -------------------------------
train_data = datasets.ImageFolder(train_dir, transform=train_tf)
valid_data = datasets.ImageFolder(valid_dir, transform=valid_tf)

train_loader = DataLoader(train_data, batch_size=32, shuffle=True, num_workers=2)
valid_loader = DataLoader(valid_data, batch_size=32, shuffle=False, num_workers=2)

num_classes = len(train_data.classes)
print("Classes:", train_data.classes)

# -------------------------------
# 4. EfficientNet-B0 (Fast + Accurate)
# -------------------------------
model = models.efficientnet_b0(weights=models.EfficientNet_B0_Weights.IMAGENET1K_V1)

# Replace last layer
model.classifier[1] = nn.Linear(model.classifier[1].in_features, num_classes)

model = model.to(device)

# -------------------------------
# 5. Loss + Optimizer
# -------------------------------
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=0.0005)

# -------------------------------
# 6. Training Loop (FAST + AMP)
# -------------------------------
epochs = 8
scaler = torch.cuda.amp.GradScaler()

start = time.time()

for epoch in range(epochs):
    model.train()
    total = 0
    correct = 0

    for images, labels in train_loader:
        images, labels = images.to(device), labels.to(device)

        optimizer.zero_grad()

        # AMP (Auto Mixed Precision)
        with torch.cuda.amp.autocast():
            outputs = model(images)
            loss = criterion(outputs, labels)

        scaler.scale(loss).backward()
        scaler.step(optimizer)
        scaler.update()

        _, preds = torch.max(outputs, 1)
        correct += (preds == labels).sum().item()
        total += labels.size(0)

    train_acc = correct / total

    # ---------------- validation ----------------
    model.eval()
    val_correct = 0
    val_total = 0

    with torch.no_grad():
        for images, labels in valid_loader:
            images, labels = images.to(device), labels.to(device)
            outputs = model(images)
            _, preds = torch.max(outputs, 1)
            val_correct += (preds == labels).sum().item()
            val_total += labels.size(0)

    val_acc = val_correct / val_total

    print(f"Epoch {epoch+1}/{epochs} | "
          f"Train Acc: {train_acc:.3f} | Val Acc: {val_acc:.3f}")

end = time.time()
print("Training time:", round(end - start, 2), "seconds")

# -------------------------------
# 7. Save Model
# -------------------------------
torch.save(model.state_dict(), "fast_plant_model.pth")
print("Model saved as fast_plant_model.pth")

import os
import random
import numpy as np
import matplotlib.pyplot as plt
from PIL import Image
import torch
import torch.nn.functional as F
import cv2

def apply_gradcam(model, img_path, transform, label_encoder, device, layer_name='conv_block5'):
    model.eval()

    # Placeholders for hooks
    activations = None
    gradients = None

    def forward_hook(module, input, output):
        nonlocal activations
        activations = output

    def backward_hook(module, grad_input, grad_output):
        nonlocal gradients
        # grad_output is a tuple, we usually want the first element
        gradients = grad_output[0]

    # --- 1. Select the target layer safely ---
    target_layer = None
    if hasattr(model, layer_name):
         # If layer_name is a direct attribute (e.g., model.layer4)
        target_layer = getattr(model, layer_name)
        # If it's a sequential block and we need the last layer, adjust logic here:
        if isinstance(target_layer, torch.nn.Sequential):
             target_layer = target_layer[-1] # Target the last convolution in the block
    else:
        # Fallback/Custom logic based on your specific model structure
        # (You might need to adjust these strings based on your model definition)
        if layer_name == 'conv_block5' and hasattr(model, 'conv_block5'):
            target_layer = model.conv_block5[0]
        elif layer_name == 'conv_block4' and hasattr(model, 'conv_block4'):
            target_layer = model.conv_block4[0]
        elif layer_name == 'conv_block3' and hasattr(model, 'conv_block3'):
            target_layer = model.conv_block3[0]

    if target_layer is None:
        print(f"Error: Layer '{layer_name}' not found in model.")
        return

    # --- 2. Register Hooks ---
    # Use register_full_backward_hook instead of the deprecated register_backward_hook
    forward_handle = target_layer.register_forward_hook(forward_hook)
    backward_handle = target_layer.register_full_backward_hook(backward_hook)

    try:
        # --- 3. Prepare Image ---
        img = Image.open(img_path).convert('RGB')
        input_tensor = transform(img).unsqueeze(0).to(device)

        # CRITICAL FIX: We need gradients for the input even in eval mode for Grad-CAM
        input_tensor.requires_grad_()

        # --- 4. Forward Pass ---
        output = model(input_tensor)
        pred_idx = output.argmax(dim=1).item()

        # Handle label encoder possibly being a list or an object
        if hasattr(label_encoder, 'inverse_transform'):
            pred_class = label_encoder.inverse_transform([pred_idx])[0]
        else:
            pred_class = label_encoder[pred_idx] # If it's just a list

        # --- 5. Backward Pass ---
        model.zero_grad()

        # Backward on the score of the predicted class
        score = output[:, pred_idx]
        score.backward()

        # --- 6. Generate Heatmap ---
        if activations is not None and gradients is not None:
            # Global Average Pooling on gradients
            pooled_gradients = torch.mean(gradients, dim=[0, 2, 3])

            # Weight the channels by corresponding gradients
            # activations shape: [1, channels, H, W]
            for i in range(activations.size(1)):
                activations[:, i, :, :] *= pooled_gradients[i]

            # Average the channels of the activations
            heatmap = torch.mean(activations, dim=1).squeeze().detach().cpu().numpy()

            # ReLU on top of the heatmap
            heatmap = np.maximum(heatmap, 0)

            # Normalize heatmap
            if np.max(heatmap) > 0:
                heatmap /= np.max(heatmap)
            else:
                print("Warning: Heatmap is empty (zeros).")

            # Resize heatmap to original image size
            original_img = np.array(img)
            heatmap = cv2.resize(heatmap, (original_img.shape[1], original_img.shape[0]))

            # Convert to RGB color map
            heatmap = np.uint8(255 * heatmap)
            heatmap_color = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)

            # Overlay
            superimposed = cv2.addWeighted(original_img, 0.6, cv2.cvtColor(heatmap_color, cv2.COLOR_BGR2RGB), 0.4, 0)

            # --- 7. Plotting ---
            plt.figure(figsize=(15, 5))

            plt.subplot(1, 3, 1)
            plt.imshow(original_img)
            plt.title("Original Image")
            plt.axis('off')

            plt.subplot(1, 3, 2)
            plt.imshow(cv2.cvtColor(heatmap_color, cv2.COLOR_BGR2RGB))
            plt.title("Grad-CAM Heatmap")
            plt.axis('off')

            plt.subplot(1, 3, 3)
            plt.imshow(superimposed)
            plt.title(f"Prediction: {pred_class}")
            plt.axis('off')

            plt.show()
        else:
            print("Could not generate activations or gradients. Check layer connection.")

    except Exception as e:
        print(f"An error occurred during Grad-CAM: {e}")
        import traceback
        traceback.print_exc()

    finally:
        # Clean up hooks
        forward_handle.remove()
        backward_handle.remove()

def generate_gradcam_visualizations(model, transform, label_encoder, device, data_dir, num_samples=2):
    print("\nüîç Generating Grad-CAM visualizations...")
    sample_images = []

    if not os.path.exists(data_dir):
        print(f"Error: Data directory '{data_dir}' does not exist.")
        return

    for disease_folder in os.listdir(data_dir):
        disease_folder_path = os.path.join(data_dir, disease_folder)
        if not os.path.isdir(disease_folder_path):
            continue

        img_files = [f for f in os.listdir(disease_folder_path) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]
        if img_files:
            # Try to grab a random image
            selected_img = os.path.join(disease_folder_path, random.choice(img_files))
            sample_images.append((selected_img, disease_folder))

    if sample_images:
        samples_to_visualize = random.sample(sample_images, min(num_samples, len(sample_images)))
        for i, (img_path, true_label) in enumerate(samples_to_visualize):
            print(f"\nVisualizing sample {i+1} - True Label: {true_label}")
            # Ensure you pass the correct layer name for YOUR model architecture here
            apply_gradcam(model, img_path, transform, label_encoder, device, layer_name='conv_block5')
    else:
        print("No sample images found in the directory structure.")

import os
import random
import numpy as np
import matplotlib.pyplot as plt
from PIL import Image
import torch
import cv2
import torchvision.models as models

# ==========================================
# 1. HIGH-ACCURACY GRAD-CAM LOGIC
# ==========================================
def apply_gradcam_high_accuracy(model, img_path, transform, device, layer_name='conv_block5', threshold=0.4):
    model.eval()
    activations = None
    gradients = None

    # Hooks
    def forward_hook(module, input, output):
        nonlocal activations
        activations = output

    def backward_hook(module, grad_input, grad_output):
        nonlocal gradients
        gradients = grad_output[0]

    # Automatic Layer Detection (Expanded)
    target_layer = None
    if hasattr(model, layer_name): target_layer = getattr(model, layer_name)
    elif hasattr(model, 'layer4'): target_layer = model.layer4[-1]       # ResNet
    elif hasattr(model, 'features'): target_layer = model.features[-1]   # VGG/AlexNet/DenseNet
    elif hasattr(model, 'conv_block5'): target_layer = model.conv_block5[0]

    if target_layer is None:
        print(f"‚ùå Error: Could not find layer. Check model architecture.")
        return

    h1 = target_layer.register_forward_hook(forward_hook)
    h2 = target_layer.register_full_backward_hook(backward_hook)

    try:
        # Load Image
        img = Image.open(img_path).convert('RGB')
        input_tensor = transform(img).unsqueeze(0).to(device)
        input_tensor.requires_grad_()

        # Forward
        output = model(input_tensor)
        pred_idx = output.argmax(dim=1).item()
        confidence = torch.softmax(output, dim=1)[0][pred_idx].item()

        # Backward
        model.zero_grad()
        output[:, pred_idx].backward()

        if activations is None or gradients is None:
            return

        # --- KEY IMPROVEMENT: Weighted Activation ---
        pooled_gradients = torch.mean(gradients, dim=[0, 2, 3])
        for i in range(activations.size(1)):
            activations[:, i, :, :] *= pooled_gradients[i]

        heatmap = torch.mean(activations, dim=1).squeeze().detach().cpu().numpy()
        heatmap = np.maximum(heatmap, 0) # ReLU

        # Normalize
        if np.max(heatmap) > 0:
            heatmap /= np.max(heatmap)

        # --- ACCURACY BOOST 1: Thresholding ---
        # Any pixel with less than 40% intensity is set to 0.
        # This removes the "blue noise" background.
        heatmap[heatmap < threshold] = 0

        # Visualization
        original_img = np.array(img)
        heatmap_resized = cv2.resize(heatmap, (original_img.shape[1], original_img.shape[0]))

        heatmap_uint8 = np.uint8(255 * heatmap_resized)
        heatmap_color = cv2.applyColorMap(heatmap_uint8, cv2.COLORMAP_JET)
        heatmap_rgb = cv2.cvtColor(heatmap_color, cv2.COLOR_BGR2RGB)

        # --- ACCURACY BOOST 2: Masking ---
        # Instead of painting the whole image blue, we only paint the 'hot' parts.
        # Create a mask where heatmap is strong
        mask = heatmap_resized > 0
        mask = np.stack([mask]*3, axis=-1) # Make it 3-channel

        # Start with original image
        superimposed = original_img.copy()

        # Only blend colors where the heatmap is active
        # (0.5 original + 0.5 heat)
        np.putmask(superimposed, mask, cv2.addWeighted(original_img, 0.5, heatmap_rgb, 0.5, 0))

        # Plotting
        plt.figure(figsize=(15, 5))

        plt.subplot(1, 3, 1)
        plt.imshow(original_img)
        plt.title(f"Original")
        plt.axis('off')

        plt.subplot(1, 3, 2)
        plt.imshow(heatmap_rgb)
        plt.title("Raw Heatmap (Thresholded)")
        plt.axis('off')

        plt.subplot(1, 3, 3)
        plt.imshow(superimposed)
        plt.title(f"Affected Area (Conf: {confidence:.2f})")
        plt.axis('off')

        plt.tight_layout()
        plt.show()
        print(f"‚úÖ Processed: {os.path.basename(img_path)}")

    except Exception as e:
        print(f"Error: {e}")
    finally:
        h1.remove()
        h2.remove()

# ==========================================
# 2. SCANNING LOGIC
# ==========================================
def scan_and_visualize(dataset_path, model, transform, num_images=3):
    print(f"\nüìÇ Scanning dataset at: {dataset_path}")

    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model = model.to(device)

    all_image_paths = []

    if not os.path.exists(dataset_path):
        print(f"‚ùå Error: Path '{dataset_path}' does not exist.")
        return

    for root, dirs, files in os.walk(dataset_path):
        for file in files:
            if file.lower().endswith(('.png', '.jpg', '.jpeg')):
                full_path = os.path.join(root, file)
                folder_name = os.path.basename(root)
                all_image_paths.append((full_path, folder_name))

    if not all_image_paths:
        print("‚ùå No images found!")
        return

    print(f"Found {len(all_image_paths)} images.")
    selected_samples = random.sample(all_image_paths, min(num_images, len(all_image_paths)))

    for img_path, label in selected_samples:
        print(f"\nTesting Image from: '{label}'")
        # üî• TWEAK THIS: Increase threshold (0.5) for tighter spots, decrease (0.3) for larger areas
        apply_gradcam_high_accuracy(model, img_path, transform, device, layer_name='conv_block5', threshold=0.45)

# ==========================================
# 3. SETUP (ADJUST THIS PART)
# ==========================================

# ‚ö†Ô∏è IMPORTANT: Point this to your .pth MODEL file, not the dataset folder!
# If you don't have a trained model file yet, keep the dummy line below enabled.
MODEL_FILE_PATH = "my_trained_model.pth"

try:
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    # Uncomment the line below if you have your .pth file ready
    # model = torch.load(MODEL_FILE_PATH, map_location=device)

    # --- TEMPORARY DUMMY MODEL (For testing code logic only) ---
    print("‚ö†Ô∏è Using ResNet50 for demonstration (Replace with your own model)")
    model = models.resnet50(pretrained=True)
    # -----------------------------------------------------------

    print("‚úÖ Model loaded.")
except Exception as e:
    print(f"‚ùå Model Load Error: {e}")

# Transforms
transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])

# Path to Images
DATA_DIR = "/kaggle/input/new-plant-diseases-dataset/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)"

if __name__ == "__main__":
    scan_and_visualize(DATA_DIR, model, transform, num_images=3)

import os
import json
import random
import torch
import torch.nn as nn
import numpy as np
import matplotlib.pyplot as plt
from PIL import Image
from matplotlib.gridspec import GridSpec
from torchvision import transforms, models

# ==========================================
# 1. TREATMENT DICTIONARY
# ==========================================
TREATMENT_RECOMMENDATIONS ={
  "Apple___Apple_scab": [
    "Apply fungicides (captan or sulfur) when leaves first appear.",
    "Rake and destroy fallen leaves to reduce overwintering spores.",
    "Plant resistant apple varieties.",
    "Prune trees to allow sunlight and air circulation."
  ],
  "Apple___Black_rot": [
    "Remove and destroy mummified fruit and dead wood.",
    "Apply fungicides (captan or thiophanate-methyl).",
    "Prune trees to increase airflow and dry foliage faster.",
    "Avoid wounding trees during harvest."
  ],
  "Apple___Cedar_apple_rust": [
    "Remove nearby juniper/cedar trees (alternate hosts) within a 2-mile radius.",
    "Apply fungicides (myclobutanil or sulfur) at the pink bud stage.",
    "Plant resistant apple varieties.",
    "Prune galls from cedar trees if removal isn't possible."
  ],
  "Apple___healthy": [
    "Maintain regular watering and fertilization schedule.",
    "Prune annually to maintain shape and airflow.",
    "Monitor for early signs of pests.",
    "Ensure soil drainage is adequate."
  ],
  "Blueberry___healthy": [
    "Maintain acidic soil (pH 4.5-5.5).",
    "Mulch with pine bark or sawdust to retain moisture.",
    "Ensure consistent watering, especially during fruit set.",
    "Prune older canes to encourage new growth."
  ],
  "Cherry_(including_sour)___Powdery_mildew": [
    "Apply fungicides (sulfur or potassium bicarbonate).",
    "Prune to improve air circulation and light penetration.",
    "Avoid overhead watering to keep foliage dry.",
    "Remove and destroy infected leaves in autumn."
  ],
  "Cherry_(including_sour)___healthy": [
    "Provide full sun and well-draining soil.",
    "Fertilize in early spring.",
    "Prune dead or diseased branches annually.",
    "Protect fruit from birds using netting."
  ],
  "Corn_(maize)___Cercospora_leaf_spot Gray_leaf_spot": [
    "Rotate crops with non-host plants for at least 2 years.",
    "Plant resistant corn hybrids.",
    "Plow under crop debris to reduce fungus survival.",
    "Apply fungicides (azoxystrobin or pyraclostrobin) if infection is severe."
  ],
  "Corn_(maize)___Common_rust_": [
    "Plant resistant hybrids (most effective method).",
    "Apply fungicides early if pustules appear on lower leaves.",
    "Destroy volunteer corn plants.",
    "Monitor fields closely during cool, moist weather."
  ],
  "Corn_(maize)___Northern_Leaf_Blight": [
    "Plant resistant hybrids.",
    "Rotate crops to reduce inoculum levels.",
    "Apply foliar fungicides during the silking stage.",
    "Manage crop residue by tillage."
  ],
  "Corn_(maize)___healthy": [
    "Ensure adequate nitrogen fertilization.",
    "Control weeds to reduce competition.",
    "Maintain consistent soil moisture.",
    "Monitor for pests like corn earworm."
  ],
  "Grape___Black_rot": [
    "Remove and destroy mummified berries and infected canes.",
    "Apply fungicides (mancozeb or myclobutanil) from bud break to fruit set.",
    "Prune for good air circulation.",
    "Weed underneath vines to increase airflow."
  ],
  "Grape___Esca_(Black_Measles)": [
    "Prune out infected wood well below visible symptoms.",
    "Protect pruning wounds with sealant.",
    "Remove and burn dead vines immediately.",
    "There is no chemical cure; prevention is key."
  ],
  "Grape___Leaf_blight_(Isariopsis_Leaf_Spot)": [
    "Apply fungicides used for other grape diseases (often managed concurrently).",
    "Improve air circulation through pruning.",
    "Maintain vine health through proper fertilization.",
    "Remove debris from the vineyard floor."
  ],
  "Grape___healthy": [
    "Prune annually during dormancy.",
    "Train vines to a trellis system.",
    "Monitor nutrient levels (especially magnesium and iron).",
    "Ensure proper irrigation without waterlogging."
  ],
  "Orange___Haunglongbing_(Citrus_greening)": [
    "There is no cure; remove and destroy infected trees immediately.",
    "Control Asian Citrus Psyllid (the vector) with insecticides.",
    "Use disease-free nursery stock.",
    "Inspect trees regularly for yellowing shoots."
  ],
  "Peach___Bacterial_spot": [
    "Plant resistant varieties.",
    "Apply copper-based sprays during dormancy.",
    "Avoid heavy nitrogen fertilization which promotes susceptible growth.",
    "Maintain plant vigor with proper pruning."
  ],
  "Peach___healthy": [
    "Prune to an open center shape for light penetration.",
    "Thin fruit to improve size and quality.",
    "Apply dormant oil sprays to control scale and mites.",
    "Water deeply during dry spells."
  ],
  "Pepper,_bell___Bacterial_spot": [
    "Use disease-free certified seeds.",
    "Rotate crops (avoid peppers/tomatoes in same spot for 3-4 years).",
    "Apply copper bactericides.",
    "Avoid overhead irrigation."
  ],
  "Pepper,_bell___healthy": [
    "Stake plants to support heavy fruit load.",
    "Maintain consistent moisture to prevent blossom end rot.",
    "Mulch to suppress weeds and retain moisture.",
    "Harvest regularly to encourage production."
  ],
  "Potato___Early_blight": [
    "Apply fungicides (chlorothalonil or mancozeb).",
    "Practice crop rotation.",
    "Keep plants vigorous with adequate nitrogen.",
    "Remove infected lower leaves."
  ],
  "Potato___Late_blight": [
    "Destroy all infected plants immediately (highly contagious).",
    "Apply preventative fungicides.",
    "Use certified disease-free seed potatoes.",
    "Eliminate cull piles and volunteer potatoes."
  ],
  "Potato___healthy": [
    "Hill soil around stems to protect tubers.",
    "Maintain consistent soil moisture.",
    "Monitor for potato beetles.",
    "Harvest after vines have died back."
  ],
  "Raspberry___healthy": [
    "Prune canes that have fruited (floricanes).",
    "Maintain rows to 1-2 feet wide.",
    "Mulch to keep roots cool and moist.",
    "Support canes with a trellis."
  ],
  "Soybean___healthy": [
    "Ensure proper spacing.",
    "Monitor for soybean aphids.",
    "Maintain soil pH between 6.0 and 6.8.",
    "Practice weed management."
  ],
  "Squash___Powdery_mildew": [
    "Apply fungicides (neem oil, sulfur, or potassium bicarbonate).",
    "Plant resistant varieties.",
    "Space plants widely for air circulation.",
    "Water at the base to keep leaves dry."
  ],
  "Strawberry___Leaf_scorch": [
    "Remove and burn infected leaves.",
    "Apply fungicides (captan or copper).",
    "Keep the patch weed-free to reduce moisture.",
    "Renovate beds immediately after harvest."
  ],
  "Strawberry___healthy": [
    "Mulch with straw to keep fruit off the soil.",
    "Remove runners to focus energy on fruit (if desired).",
    "Ensure full sun exposure.",
    "Water 1-2 inches per week."
  ],
  "Tomato___Bacterial_spot": [
    "Remove and destroy infected plants.",
    "Spray with copper fungicides.",
    "Avoid working in wet plants.",
    "Rotate crops for at least 2 years."
  ],
  "Tomato___Early_blight": [
    "Trim off infected lower leaves.",
    "Apply mulch to prevent soil splash.",
    "Stake plants to improve airflow.",
    "Apply fungicide if symptoms persist."
  ],
  "Tomato___Late_blight": [
    "Remove entire infected plant and destroy (do not compost).",
    "Apply copper-based fungicide preventatively.",
    "Water only at the base of the plant.",
    "Ensure wide spacing between plants."
  ],
  "Tomato___Leaf_Mold": [
    "Increase ventilation (crucial in greenhouses).",
    "Apply fungicide (chlorothalonil).",
    "Remove lower leaves to improve airflow.",
    "Reduce humidity levels."
  ],
  "Tomato___Septoria_leaf_spot": [
    "Remove infected leaves immediately.",
    "Apply fungicide (chlorothalonil).",
    "Practice crop rotation.",
    "Clean up all crop debris at end of season."
  ],
  "Tomato___Spider_mites Two-spotted_spider_mite": [
    "Spray with a strong stream of water to dislodge mites.",
    "Apply insecticidal soap or neem oil.",
    "Introduce predatory mites.",
    "Keep plants well-watered (mites love hot, dry conditions)."
  ],
  "Tomato___Target_Spot": [
    "Remove old plant debris.",
    "Apply fungicides (azoxystrobin).",
    "Improve air circulation.",
    "Avoid overhead irrigation."
  ],
  "Tomato___Tomato_Yellow_Leaf_Curl_Virus": [
    "Remove and destroy infected plants immediately.",
    "Control whiteflies (vectors) with sticky traps or sprays.",
    "Use reflective mulches.",
    "Plant resistant varieties (look for 'TY' on labels)."
  ],
  "Tomato___Tomato_mosaic_virus": [
    "Remove infected plants; there is no cure.",
    "Wash hands thoroughly (virus spreads by touch/tobacco).",
    "Disinfect tools with bleach solution.",
    "Control aphids."
  ],
  "Tomato___healthy": [
    "Stake or cage plants for support.",
    "Water deeply and consistently.",
    "Fertilize with tomato-specific fertilizer.",
    "Prune 'suckers' for better fruit production."
  ]

}

# ==========================================
# 2. MODEL UTILITIES (FIXED FOR EFFICIENTNET)
# ==========================================
def get_model(num_classes, device):
    """
    Creates EfficientNet-B0 architecture to match your training script.
    """
    # Load EfficientNet B0 (No weights needed as we load state_dict later)
    model = models.efficientnet_b0(weights=None)

    # Replace final layer to match your 38 classes
    # EfficientNet uses 'classifier', not 'fc'
    model.classifier[1] = nn.Linear(model.classifier[1].in_features, num_classes)

    return model.to(device)

def get_default_transform():
    """Standard transform for inference"""
    # Important: Your training used 128x128 resize
    return transforms.Compose([
        transforms.Resize((128, 128)),
        transforms.ToTensor()
    ])

# ==========================================
# 3. INTERACTIVE DIAGNOSIS FUNCTION
# ==========================================
def interactive_disease_diagnosis(model_path, dataset_dir):

    # 1. Setup Device
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"üöÄ Running on {device}")

    # 2. Scan Directory
    if not os.path.exists(dataset_dir):
        print(f"‚ùå Error: Dataset directory '{dataset_dir}' not found.")
        return

    # Filter out hidden files
    class_names = sorted([d for d in os.listdir(dataset_dir)
                         if os.path.isdir(os.path.join(dataset_dir, d))
                         and not d.startswith('.')])

    num_classes = len(class_names)
    print(f"üìÇ Found {num_classes} disease classes.")

    if num_classes == 0:
        print("‚ùå No classes found. Check dataset path.")
        return

    # 3. Load Model
    try:
        model = get_model(num_classes, device)

        if torch.cuda.is_available():
            loaded_data = torch.load(model_path)
        else:
            loaded_data = torch.load(model_path, map_location=torch.device('cpu'))

        if isinstance(loaded_data, dict) and 'state_dict' in loaded_data:
            model.load_state_dict(loaded_data['state_dict'])
        elif isinstance(loaded_data, dict):
             model.load_state_dict(loaded_data)
        else:
            # Fallback if the user saved the entire model object
            model = loaded_data

        model.eval()
        print("‚úÖ Model loaded successfully.")
    except Exception as e:
        print(f"‚ùå Error loading model: {e}")
        return

    # 4. Transform
    transform = get_default_transform()

    # 5. Gather Test Images
    test_images = []
    for cls in class_names:
        folder_path = os.path.join(dataset_dir, cls)
        images = [f for f in os.listdir(folder_path) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]
        if images:
            selected = random.choice(images)
            test_images.append((os.path.join(folder_path, selected), cls))

    # Select 6 random images
    num_display = min(6, len(test_images))
    if num_display == 0:
        print("‚ùå No images found in dataset folders.")
        return

    selected_samples = random.sample(test_images, num_display)

    # 6. Visualization
    plt.rcParams.update({'font.size': 10})
    fig = plt.figure(figsize=(20, 15))
    gs = GridSpec(2, 3, figure=fig)

    fig.suptitle("üåø AI Plant Disease Diagnosis", fontsize=24, fontweight='bold', y=0.98, color='green')

    for i, (img_path, true_label) in enumerate(selected_samples):
        row = i // 3
        col = i % 3
        ax = fig.add_subplot(gs[row, col])

        # A. Predict
        try:
            img = Image.open(img_path).convert('RGB')
            img_tensor = transform(img).unsqueeze(0).to(device)

            with torch.no_grad():
                outputs = model(img_tensor)
                probs = torch.nn.functional.softmax(outputs, dim=1)[0]

            conf, pred_idx = torch.max(probs, 0)
            pred_class = class_names[pred_idx.item()]
            confidence = conf.item() * 100

        except Exception as e:
            print(f"Prediction error on {img_path}: {e}")
            continue

        # B. Display
        ax.imshow(img)
        ax.axis('off')

        # C. Status
        is_correct = (pred_class == true_label)
        status_color = 'green' if is_correct else 'red'

        # D. Recommendations
        recs = TREATMENT_RECOMMENDATIONS.get(pred_class,
               TREATMENT_RECOMMENDATIONS.get(pred_class.replace(" ", "_"), ["No specific data."]))

        rec_text = "\n".join([f"‚Ä¢ {r}" for r in recs[:3]])

        # E. Overlay
        title = f"Pred: {pred_class}\nConf: {confidence:.1f}%"
        ax.set_title(title, fontsize=12, fontweight='bold',
                     color='white', bbox=dict(facecolor=status_color, alpha=0.8, boxstyle='round'))

        plt.figtext(
            (col * 0.33) + 0.02,
            (0.53 if row == 0 else 0.05),
            f"TREATMENT:\n{rec_text}",
            fontsize=9, bbox=dict(facecolor='#f0f0f0', alpha=0.9, boxstyle='round')
        )

    plt.tight_layout(rect=[0, 0.1, 1, 0.95])
    plt.show()

# ==========================================
# 4. RUNNER
# ==========================================
if __name__ == "__main__":
    # Pointing to the file you saved in your training step: "fast_plant_model.pth"
    MODEL_FILE = "fast_plant_model.pth"

    # Pointing to the VALIDATION folder which has the class subfolders
    DATASET_FOLDER = "/kaggle/input/new-plant-diseases-dataset/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/valid"

    if os.path.exists(MODEL_FILE) and os.path.exists(DATASET_FOLDER):
        interactive_disease_diagnosis(MODEL_FILE, DATASET_FOLDER)
    else:
        print(f"‚ö†Ô∏è Check paths:\nModel exists: {os.path.exists(MODEL_FILE)}\nDataset exists: {os.path.exists(DATASET_FOLDER)}")

